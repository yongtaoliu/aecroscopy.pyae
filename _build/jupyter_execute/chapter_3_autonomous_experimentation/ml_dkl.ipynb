{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc2cadf",
   "metadata": {},
   "source": [
    "# Deep Kernel Learning driven piezoresponse spectroscopy\n",
    "\n",
    "$_{Yongtao}$ $_{Liu,}$ $_{liuy3@ornl.gov}$\n",
    "\n",
    "$_{July}$ $_{2023}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbff04b",
   "metadata": {},
   "source": [
    "### Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import win32com.client\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import sidpy\n",
    "import pyNSID\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import h5py\n",
    "from mlsocket import MLSocket\n",
    "\n",
    "# import acquition.py\n",
    "from Acquisition_v0_5 import Acquisition   # include the Acquistion_v0.py in the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c05a8",
   "metadata": {},
   "source": [
    "### Start BEPyAE.exe and set VI\n",
    "\n",
    "* Start BEPyAE.ext\n",
    "* Set VI of BEPyAE; if this version includes PyScanner, also set VIs for PyScanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ee86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp = Acquisition(exe_path = r\"C:\\BEPyAE 060123 01\\BEPyAE.exe\")   # exe_path is the directory of BEPyAE; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f421fa",
   "metadata": {},
   "source": [
    "### Initialize Igor AR18\n",
    "* Set offline development\n",
    "* Build a connection between BEPyAE and AR18\n",
    "* Get parameters in AR18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b51e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp.init_BEPyAE(offline_development = True) # set offline_development=True if doing offline development\n",
    "                                                # executing this will also initlize AR18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ab303",
   "metadata": {},
   "source": [
    "### Set tip parameters\n",
    "* set setpoint, tip locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7484a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setpoint is:  1.0\n",
      "Tip parameters are:  (-0.5, 0.5, 0.5)\n",
      "Please reset if some parameters are incorrect\n"
     ]
    }
   ],
   "source": [
    "newexp.tip_control(tip_parms_dict = {\"set_point_V_00\": 1, \"next_x_pos_00\": -0.5, \"next_y_pos_01\": 0.5},\n",
    "                   do_move_tip = True, \n",
    "                   do_set_setpoint = True) # Executing this code will set setpoint to 1 V, \n",
    "                                           # and move tip to location [0.5, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3d6d5",
   "metadata": {},
   "source": [
    "### Set IO \n",
    "This defines IO parameters, such as AFM platform: AR18, amplifiers, channel data types, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3eb5cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO control parameters are:  ('0 Cypher AR18', '6124', 4000000.0, 10.0, 10.0, 'AC and DC on AO0', 10.0, 'topography', 'current', 'aux', 'external')\n",
      "Please reset if some parameters are incorrect\n"
     ]
    }
   ],
   "source": [
    "newexp.define_io_cluster(IO_cluster_parms_dict = {\"analog_output_amplifier_06\": 1, \n",
    "                                                  \"channel_01_type_07\": 1, \n",
    "                                                  \"channel_02_type_08\": 2,\"channel_03_type_09\": 3,})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b917f",
   "metadata": {},
   "source": [
    "### Set BE pulse parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b332c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE parameters are:  (335000.0, 100000.0, 1.0, 1.0, 4, 0.004, 1, 3352.2952763920002, 0.12159459061880915)\n",
      "Please reset if some parameters are incorrect\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(335000.0,\n",
       " 100000.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4,\n",
       " 0.004,\n",
       " 1,\n",
       " 3352.2952763920002,\n",
       " 0.12159459061880915)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set BE parameters\n",
    "newexp.define_be_parms(be_parms_dict = {\"center_frequency_Hz_00\": 335, \"band_width_Hz_01\": 100,\n",
    "                                       \"amplitude_V_02\": 1, \"phase_variation_03\": 1,\n",
    "                                       \"repeats_04\": 4, \"req_pulse_duration_s_05\": 4,\n",
    "                                       \"auto_smooth_ring_06\": 1}, \n",
    "                      do_create_be_waveform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af23d31",
   "metadata": {},
   "source": [
    "### BE Line scan to test BE parameters\n",
    "* This is a single BE line scan\n",
    "* This returns 5 datasets: quick_fitting, complex spectra, and 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a2d63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voltage offset and number of BE pulse are:  (0.0, 32)\n",
      "line scan start and end positions:  (-0.5, 0.0, 0.5, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Do a single line scan\n",
    "qk_fit, com_spec, chn1, chn2, chn3 = newexp.do_line_scan(line_scan_parms_dict = {\"num_BE_pulses_01\": 32,\n",
    "                                                                                 \"start_x_pos_00\": -0.5, \"start_y_pos_01\": 0,\n",
    "                                                                                 \"stop_x_pos_02\": 0.5, \"stop_y_pos_03\": 0},\n",
    "                                                         upload_to_daq = True, do_line_scan = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ddb0f",
   "metadata": {},
   "source": [
    "# Experiment Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855c0ee",
   "metadata": {},
   "source": [
    "```{admonition} Run on local PC\n",
    "Run below code on microscope computer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a600bf",
   "metadata": {},
   "source": [
    "### Prior to expeirment, set a directory to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f44615e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/save directory/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25324/3425510952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/save directory/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/save directory/'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/content/save directory/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f840f68",
   "metadata": {},
   "source": [
    "### Step 1. Perform a BEPFM measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23cdb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 locations are ready for experiments\n"
     ]
    }
   ],
   "source": [
    "dset_pfm, dset_chns, dset_cs = newexp.raster_scan(raster_parms_dict = {\"scan_pixel\": 256, \"scan_x_start\": -1.0,\n",
    "                                                                       \"scan_y_start\": -1.0,\"scan_x_stop\": 1.0,\n",
    "                                                                       \"scan_y_stop\": 1.0}, file_name = \"BEPFM\")\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize = (30, 5), dpi = 100)\n",
    "ax1.imshow(dset_pfm[:,:,0])\n",
    "ax2.imshow(dset_pfm[:,:,1])\n",
    "ax3.imshow(dset_pfm[:,:,2])\n",
    "ax4.imshow(dset_pfm[:,:,3])\n",
    "ax5.imshow(dset_chns[0,:,:])\n",
    "ax6.imshow(dset_chns[1,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea0132",
   "metadata": {},
   "source": [
    "### Step 2. Prepare structure patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize structure data\n",
    "norm_ = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "struc_img = np.asarray(dset_pfm[:,:,0])          # set structure image\n",
    "struc_img = norm_(struc_img)   # normalize\n",
    "\n",
    "np.save('structure_image.npy', struc_img)  # send this to GPU server later\n",
    "\n",
    "print (\"Structure image shape:\", struc_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65884d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare structure image patches\n",
    "coordinates = utils.get_coord_grid(struc_img, 1)\n",
    "\n",
    "# patch size\n",
    "window_size = 20\n",
    "pix = struc_img.shape[1] - window_size + 1\n",
    "\n",
    "# extract subimage for each point on a grid\n",
    "features_all, coords, _ = utils.extract_subimages(struc_img, coordinates, window_size)\n",
    "features_all = features_all[:,:,:,0]\n",
    "# indices = coords.reshape(pix,pix,2)\n",
    "indices = coords\n",
    "\n",
    "print(\"Patch shape:\", features_all.shape)\n",
    "print(\"Indices list shape: \", indices.shape)\n",
    "\n",
    "# plot structure image and an example patch\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, dpi = 100)\n",
    "k = 20\n",
    "ax1.imshow(struc_img, origin = \"lower\")\n",
    "ax1.scatter(indices.reshase(-1, 2)[k, 1], indices.reshape(-1, 2)[k, 0], c = 'r')\n",
    "ax2.imshow(features_all[k], origin = \"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97e90e",
   "metadata": {},
   "source": [
    "### Step 3. Send struc_img.npy to GPU server via sftp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e0c20",
   "metadata": {},
   "source": [
    "```{admonition} Run on GPU server\n",
    "Run below code on GPU server.\n",
    "```\n",
    "### Step 4. Install, import, and define help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72953186",
   "metadata": {},
   "outputs": [],
   "source": [
    "Please run this code @ GPU server\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch\n",
    "import atomai as aoi\n",
    "from atomai import utils\n",
    "# from scipy.signal import find_peaks\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from typing import Union, Type\n",
    "from mlsocket import MLSocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Please run this code @ GPU server\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "############---DKL Acquistion function---###########\n",
    "def EI(model: Type[aoi.models.dklGPR], X: Union[np.ndarray, torch.Tensor],\n",
    "       best_f: Union[float, torch.Tensor], xi: Union[float, torch.Tensor] = 0.01,\n",
    "       batch_size: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expected Improvement\n",
    "    \"\"\"\n",
    "    tt = torch.tensor\n",
    "    types = (np.ndarray, np.float32, np.float64, float)\n",
    "    tor = lambda a: tt(a) if isinstance(a, types) else a    \n",
    "    device=model.device\n",
    "    dtype = model.dtype\n",
    "    X, best_f, xi = tor(X), tor(best_f), tor(xi)\n",
    "    mean, var = model.predict(X.to(dtype).to(device), batch_size=batch_size)\n",
    "    mean, var = tor(mean), tor(var)  # have to translate them back to torch tensors\n",
    "    sigma = var.sqrt()\n",
    "    u = (mean - best_f.expand_as(mean) - xi.expand_as(mean)) / sigma\n",
    "    normal = torch.distributions.Normal(torch.zeros_like(u), torch.ones_like(u))\n",
    "    ucdf = normal.cdf(u)\n",
    "    updf = torch.exp(normal.log_prob(u))\n",
    "    obj = sigma * (updf + u * ucdf)\n",
    "    return obj.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1e61e",
   "metadata": {},
   "source": [
    "### Step 5. Prepare image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa11547",
   "metadata": {},
   "outputs": [],
   "source": [
    "Please run this code @ GPU server\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "# prepare structure image patches\n",
    "coordinates = utils.get_coord_grid(struc_img, 1)\n",
    "\n",
    "# patch size\n",
    "window_size = 20\n",
    "pix = struc_img.shape[1] - window_size + 1\n",
    "\n",
    "# extract subimage for each point on a grid\n",
    "features_all, coords, _ = utils.extract_subimages(struc_img, coordinates, window_size)\n",
    "features_all = features_all[:,:,:,0]\n",
    "# indices = coords.reshape(pix,pix,2)\n",
    "indices = coords\n",
    "\n",
    "print(\"Patch shape:\", features_all.shape)\n",
    "print(\"Indices list shape: \", indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2020c",
   "metadata": {},
   "source": [
    "```{admonition} Run on local PC\n",
    "Run below code on microscope computer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4922b32",
   "metadata": {},
   "source": [
    "### Step 6. Do first BEPS at random location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first BEPS measurement is performed at a random location\n",
    "np.random.seed(0)\n",
    "index = np.random.randint(len(indices)) # random location\n",
    "print (\"First location index: \", index)\n",
    "\n",
    "# Do beps\n",
    "do_beps(indices[index])\n",
    "print(\"measurement done\")\n",
    "    \n",
    "# Read data and calculate scalarizer\n",
    "new_spec = \n",
    "new_scalarizer = \n",
    "\n",
    "# Define a list to save scalarizer\n",
    "y_train_raw = np.asarray([])\n",
    "y_train_raw = np.append(y_train_raw, new_scalarizer)    \n",
    "print('Now, the y_train_raw is {}'.format(y_train_raw))\n",
    "        \n",
    "# Normalize y_train\n",
    "y_train_normalize = np.asarray([0.5]) # Since there is just a single value, we set it as 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21883760",
   "metadata": {},
   "source": [
    "### Step 7. Request connection to GPU server and start DKL exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0571970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exploration step\n",
    "exploration_step = 200\n",
    "\n",
    "HOST = 'localhost'\n",
    "PORT = 9000\n",
    "with MLSocket() as s:\n",
    "    s.connect((HOST, PORT))\n",
    "    for i in range (exploration_step):\n",
    "        print(\"##########----step {}/{}----##########\".format(i+1, exploration_step))\n",
    "        starttime = time.time()\n",
    "        \n",
    "        # Send the measured data to GPU server\n",
    "        new_data = np.asarray(y_train_normalize[-1])\n",
    "        s.send(new_data)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        # Listen next location\n",
    "        next_location = s.recv(920)\n",
    "        time.sleep(0.01)\n",
    "        print(\"predicted point ready\", next_location)\n",
    "        \n",
    "        ###### Do BEPS Measurement at predicted location ########\n",
    "        newexp.do_beps(next_location)\n",
    "        print(\"measurement done\")\n",
    "    \n",
    "        # Read data and calculate scalarizer\n",
    "        new_spec = \n",
    "        new_scalarizer = \n",
    "    \n",
    "        y_train_raw = np.append(y_train_raw, new_scalarizer)    \n",
    "        print('Now, the y_train_raw is {}'.format(y_train_raw))\n",
    "        \n",
    "        # Normalize y_train\n",
    "        y_train_normalize = (y_train_raw - y_train_raw.min())/y_train_raw.ptp()\n",
    "        \n",
    "        # Plot figure\n",
    "        clear_output(wait=True)\n",
    "        plt.figure()\n",
    "        plt.imshow(struc_img, cmap = 'gray')\n",
    "        plt.scatter(next_loc[0], next_loc[1], c = 'r')\n",
    "        plt.show()\n",
    "    \n",
    "        print(\"time in this step: \", time.time()-starttime)\n",
    "\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cf348",
   "metadata": {},
   "source": [
    "```{admonition} Run on GPU server\n",
    "Run below code on GPU server.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cae2e1",
   "metadata": {},
   "source": [
    "\n",
    "### Step 8. Connect to local PC and start DKL exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Please run this code @ GPU server\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "data_dim = X_train.shape[-1]\n",
    "exploration_step = 200\n",
    "xi = 0.01\n",
    "\n",
    "HOST = ''\n",
    "PORT = 3446\n",
    "\n",
    "with MLSocket() as s:\n",
    "    s.bind((HOST, PORT))\n",
    "    print(\"bounding......\\nplease bound the other end\")\n",
    "    s.listen()\n",
    "    conn, address = s.accept()\n",
    "    with conn:\n",
    "        print('DKL starts')\n",
    "        for step in range(exploration_steps):\n",
    "            print(\"##########----step {}/{}----##########\".format(step+1, exploration_steps))\n",
    "\n",
    "            if step == 0:\n",
    "                np.random.seed(0)\n",
    "                index = np.random.randint(len(indices))   # may need to manually added the random index here\n",
    "                print(\"First index: \", index)\n",
    "\n",
    "                # Update train and test data\n",
    "                X_train [0,] = X[idx,]\n",
    "                X_test = np.delete(X_test, idx, 0)\n",
    "                indices_train[0,] = indices_test[idx,]\n",
    "                indices_test = np.delete(indices_test, idx, 0)\n",
    "                \n",
    "                # Listen to client for measurement result\n",
    "                measured_point = conn.recv(920)\n",
    "                print(\"Received new point data\")\n",
    "                #update training data\n",
    "                y_train = np.append(y_train, measured_point)\n",
    "            else:\n",
    "                #listen to client for measurement result\n",
    "                measured_point = conn.recv(920)\n",
    "                print(\"received new point data\")\n",
    "                #update training data\n",
    "                y_train = np.append(y_train, measured_point)\n",
    "\n",
    "                X_med[0,] = X_test[next_point_idx,]\n",
    "                X_train = np.append(X_train, X_med, axis = 0)\n",
    "                X_test = np.delete(X_test, next_point_idx, 0)\n",
    "                indices_med[0,] = indices_test[next_point_idx]\n",
    "                indices_train = np.append(indices_train, indices_med, axis = 0)\n",
    "                indices_test = np.delete(indices_test, next_point_idx, 0)\n",
    "\n",
    "            dklgp = aoi.models.dklGPR(data_dim, embedim=2, precision=\"single\")\n",
    "            dklgp.fit(X_train, y_train, training_cycles=200)\n",
    "            # Compute acquisition function\n",
    "            # best_f = torch.tensor(dklgp.predict(X_train)[0].max(), device=dklgp.device)\n",
    "            # obj_mean = EI(dklgp, X_test, best_f, xi, batch_size = 2000)\n",
    "            # Select next point to \"measure\"\n",
    "            _, var_ = dklgp.predict(X_test, batch_size = len(X_test))\n",
    "            next_point_idx = var_.argmax()\n",
    "            next_points = np.asarray(indices_test[next_point_idx])\n",
    "            #send next point to client\n",
    "            conn.send(next_points)\n",
    "            print(\"Send next point index and next point: \", next_point_idx, next_points)\n",
    "\n",
    "            #save step record\n",
    "            np.savez(os.path.join(savedir, \"record{}.npz\".format(step)), x_train = X_train, y_train = y_train, \n",
    "            indice_train = indices_train, indice_test=indices_test, var=var_, nextpoint=next_points)\n",
    "            # np.savez((\"/exp_record/record{}.npz\".format(step)), indicestest=indices_test, \n",
    "            # objmean=obj_mean, nextpoint=next_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db598cd1",
   "metadata": {},
   "source": [
    "```{admonition} Run on local PC\n",
    "Run below code on microscope computer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6729043",
   "metadata": {},
   "source": [
    "\n",
    "### Step 8. Do a BEPFM at the whole experiment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_pfm, dset_chns, dset_cs = newexp.raster_scan(raster_parms_dict = {\"scan_pixel\": 256, \"scan_x_start\": -1.0,\n",
    "                                                                       \"scan_y_start\": -1.0,\"scan_x_stop\": 1.0,\n",
    "                                                                       \"scan_y_stop\": 1.0}, file_name = \"pfm_whole\")\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize = (30, 5), dpi = 100)\n",
    "ax1.imshow(dset_pfm[:,:,0])\n",
    "ax2.imshow(dset_pfm[:,:,1])\n",
    "ax3.imshow(dset_pfm[:,:,2])\n",
    "ax4.imshow(dset_pfm[:,:,3])\n",
    "ax5.imshow(dset_chns[0,:,:])\n",
    "ax6.imshow(dset_chns[1,:,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}